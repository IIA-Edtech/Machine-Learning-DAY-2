{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xSDP4bMrIL2x"
   },
   "source": [
    "# Simple Linear Regression\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.   **[Introduction to Linear Regression](#1.-Introduction-to-Linear-Regression)**\n",
    "1.   **[Foundations of Linear Regression](#2.-Foundations-of-Linear-Regression)**\n",
    "1.   **[Model Assumptions](#3.-Model-Assumptions)**\n",
    "1.   **[Exploratory Data Analysis](#4.-Exploratory-Data-Analysis)**\n",
    "1.   **[Model Construction](#5.-Model-Construction)**\n",
    "1.   **[Model Evaluation](#6.-Model-Evaluation)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1. Definitions\"></a>\n",
    "### 1. Introduction to Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Definitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple Linear Regression |** Technique that estimates the linear relationship between a `continuous` dependent variable and `one independent` variable. \n",
    "\n",
    "**Dependant variable (y) |** The variable a given model estimates, also referred to as a response or outcome variable\n",
    "\n",
    "**Independent variable (x) |** A variable that explains trends in the dependent variable, also referred to as an explanatory or predictor variable.\n",
    "\n",
    "**Simple Linear Regression Formula |** $y = intercept + slope(x)$\n",
    "\n",
    "**Slope |** The amount that `y` increases or decreases per one-unit increase of `x`\n",
    "\n",
    "**Intercept |** The value of `y`, the dependent variable, when `x`, the independent variable, equals 0\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Mathematical Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression Equation |** $y = \\beta_0 + \\beta_1 x + \\epsilon$\n",
    "\n",
    "parameters are properties of populations so we can never know their true values unless the entire population is observed\n",
    "\n",
    "- estimates of the parameters are calculated from sample data\n",
    "- estimates are denoted with ^ hats\n",
    "\n",
    "**Linear Regression Estimation |** $\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1} x + \\epsilon$\n",
    "\n",
    "**Regression Coefficients |** The estimated betas in a regression model. Represented as $\\hat{\\beta_i}$\n",
    "\n",
    "**Ordinary Least Squares Estimation (OLS) |** Common way to calculate linear regression coefficients $\\hat{(\\beta)}_n$ \n",
    "\n",
    "**Loss Function |** A function that measures the distance between the observed values and the model's estimated values \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Foundations of Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Ordinary Least Squares Estimation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary least squares (OLS) is a method used in linear regression analysis to estimate the unknown parameters of the linear regression model. The goal of OLS estimation is to find the values of the regression coefficients that minimize the sum of the squared errors between the predicted values and the actual values of the dependent variable.\n",
    "\n",
    "**Best Fit Line |** The line that fits the data best by minimizing some loss function or error\n",
    "\n",
    "**Predicted values |** The estimated (y) values for each (x) calculated by a model\n",
    "\n",
    "**Residual |** The difference between observed or actual values and the predicted values of the regression line \n",
    "- Residual = Observed - Predicted ---> $\\epsilon_i = y_i - \\hat{y_i}$\n",
    "\n",
    "**Sum of Squared Residuals (SSR) |** The sum of the squared differences between each observed value and its associated predicted value \n",
    "- $SSR = \\sum\\limits_{i=1}^{n}(Observed - Predicted)^2$\n",
    "- $SSR = \\sum\\limits_{i=1}^{n}(y_i - \\hat{y_i})^2$\n",
    "\n",
    "**Ordinary Least Squares (OLS) |** A method that minimizes the sum of the squared residuals to estimate parameters in a linear regression model\n",
    "- Used to calculate: $\\hat{y}=\\hat{\\beta_0} + \\hat{\\beta_1(x)}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Model Assumptions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model assumptions are statements about the data that must be true in order to justify the use of a particular modeling technique\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.1 Linear Regression Assumptions\n",
    "- **Linearity**\n",
    "- **Normality**\n",
    "- **Independent Observations**\n",
    "- **Homoscedasticity**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 3.1.1 Linearity\n",
    "\n",
    "**Each predictor variable $(x_i)$ is linearly related to the outcome variable $(y)$**\n",
    "\n",
    "##### 3.1.2 Normality\n",
    "\n",
    "**The residuals of errors are normally distributed.**\n",
    "- Can only be checked after the model is built because residuals must be known for calculation\n",
    "- Checked using a quantile-quantile plot (Q-Q plot)\n",
    "    - if points on the plot form a straight diagonal line then can assume normality\n",
    "\n",
    "##### 3.1.3 Independent Observation \n",
    "\n",
    "**Each observation in the dataset is independent**\n",
    "\n",
    "##### 3.1.4 Homoscedasticity\n",
    "\n",
    "**The variation of the residuals (errors) is constant or similar across the model**\n",
    "- Homoscedasticity means having the same scatter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.2 Assumption Violations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 3.2.1 Linearity\n",
    "**Transform one or both of the variables**, such as taking the logarithm.\n",
    "- For example, if measuring the relationship between years of education and income, take the logarithm of the income variable and check if that helps the linear relationship.\n",
    "\n",
    "##### 3.2.2 Normality\n",
    "**Transform one or both variables.** Most commonly, this would involve taking the logarithm of the outcome variable.\n",
    "- When the outcome variable is right skewed, the normality of the residuals can be affected. Taking the logarithm of the outcome variable can sometimes help with this assumption.\n",
    "- When transforming a variable, reconstruct the model and recheck the normality assumption. If the assumption is still not satisfied, continue troubleshooting the issue.\n",
    "\n",
    "##### 3.2.3 Independent Observation \n",
    "**Take just a subset of the available data.**\n",
    "- If, for example, data is a survey including responses from people in the same household, responses may be correlated. Correct for this by just keeping the data of one person in each household.\n",
    "- Another example data on bike rental over a time period. If data collected every 15 minutes, the number of bikes rented out at 8:00 a.m. might correlate with the number of bikes rented out at 8:15 a.m. Perhaps the number of bikes rented out is independent if the data is taken once every 2 hours, instead of once every 15 minutes.\n",
    "\n",
    "##### 3.2.4 Homoscedasticity\n",
    "**Define a different outcome variable.**\n",
    "- If interested in understanding how a cityâ€™s population correlates with the number of restaurants in a city, it's known that some cities are more populous than others. Therefore possibe to redefine the outcome variable as the ratio of population to restaurants instead.\n",
    "\n",
    "**Transform the Y variable.**\n",
    "- As with the above assumptions, sometimes taking the logarithm or transforming the Y variable in another way can potentially fix inconsistencies with the homoscedasticity assumption."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant Python libraries and modules\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the dataset into a DataFrame and save in a variable\n",
    "\n",
    "data = pd.read_csv(\"example_file.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 10 rows of the data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display number of rows, number of columns\n",
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Missing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1.1 Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Start with .isna() to get booleans indicating whether each value in the data is missing\n",
    "data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Use .any(axis=1) to get booleans indicating whether there are any missing values along the columns in each row\n",
    "data.isna().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Use .sum() to get the number of rows that contain missing values\n",
    "data.isna().any(axis=1).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1.2 Drop missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Use .dropna(axis=0) to indicate that you want rows which contain missing values to be dropped\n",
    "# Step 2. To update the DataFrame, reassign it to the result\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure that the data does not contain any rows with missing values now\n",
    "\n",
    "# Step 1. Start with .isna() to get booleans indicating whether each value in the data is missing\n",
    "# Step 2. Use .any(axis=1) to get booleans indicating whether there are any missing values along the columns in each row\n",
    "# Step 3. Use .sum() to get the number of rows that contain missing values\n",
    "data.isna().any(axis=1).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Model Assumptions | Initial Check\n",
    "\n",
    "Can only check for linearity at this point. The rest of the assumptions will be checked after the model is constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot of pairwise relationships to check linearity\n",
    "sns.pairplot(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5. Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "# Save resulting DataFrame in a separate variable to prepare for regression\n",
    "ols_data = data[[\"Independent variable(Column_n)\", \"Dependant variable(Column_n)\"]]\n",
    "\n",
    "# Display first 10 rows of the new DataFrame\n",
    "ols_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the linear regression formula replacing Y and X with the corresponding column names eg: Sales and Ad_Spend\n",
    "# Save it in a variable\n",
    "ols_formula = \"Dependant variable(Y) ~ Independent variable(X)\"\n",
    "\n",
    "# Implement OLS approach for linear regression\n",
    "OLS = ols(formula= ols_formula, data= ols_data)\n",
    "\n",
    "# Fit the model to the data\n",
    "# Save the fitted model in a variable\n",
    "model = OLS.fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary of results\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Summary Analysis\n",
    "\n",
    "**Questions to consider based on the results:**\n",
    "1. What is the y-intercept?\n",
    "2. What is the slope? \n",
    "3. What is the linear equation if written to express the relationship between (x) and (y) in the form of y = slope * x + y-intercept?\n",
    "4. What do you think the slope in this context means?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Model Assumptions | Final Check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.1 Normality Check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the residuals from the model\n",
    "residuals = model.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of the residuals\n",
    "fig = sns.histplot(residuals)\n",
    "fig.set_xlabel(\"Residual Value\")\n",
    "fig.set_title(\"Histogram of Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to answer:**\n",
    "\n",
    "1. Based on the visualization above, is the distribution of the residuals normal?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q-Q Plot Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Q-Q plot \n",
    "sm.qqplot(residuals, line='s')\n",
    "plt.title(\"Q-Q plot of Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to answer:**\n",
    "\n",
    "1. Do the points on the Q-Q plot closely follow a straight diagonal line trending upward?\n",
    "    - If yes then normality assumption met"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.2 Independent Observation and Homoscedasticity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fitted values\n",
    "fitted_values = model.predict(ols_data[\"Radio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot of residuals against fitted values\n",
    "fig = sns.scatterplot(x=fitted_values, y=residuals)\n",
    "fig.axhline(0)\n",
    "fig.set_xlabel(\"Fitted Values\")\n",
    "fig.set_ylabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to answer:**\n",
    "\n",
    "1. Do the data points have a cloud-like resemblance and do not follow an explicit pattern?\n",
    "    - If yes then normality assumption met"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1BgN3Lv1fx-AxyKSqB_2kM3dJ4mFBctv_",
     "timestamp": 1662734078308
    },
    {
     "file_id": "1ZYfhIvPRxnw7ghB_BsNQAMUorLXpAZs_",
     "timestamp": 1658889786811
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
