{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xSDP4bMrIL2x"
   },
   "source": [
    "# Binomial Logistic Regression\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.   **[Introduction to Logistic Regression](#1.-Introduction-to-Logistic-Regression)**\n",
    "2.   **[Foundations of Logistic Regression](#2.-Foundations-of-Logistic-Regression)**\n",
    "3.   **[Model Assumptions](#3.-Model-Assumptions)**\n",
    "4.   **[Model Interpretation](#4.-Model-Interpretation)**\n",
    "5.   **[Exploratory Data Analysis](#5.-Exploratory-Data-Analysis)**\n",
    "6.   **[Model Construction](#6.-Model-Construction)**\n",
    "7.   **[Model Results](#7.-Model-Results)**\n",
    "8.   **[Model Evaluation](#8.-Model-Evaluation)**\n",
    "9.   **[Conclusion](#9-Conclusions)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"1.-Introduction-to-Multiple-Linear-Regression\"></a>\n",
    "### 1. Introduction to Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Definitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression |** Technique that models a categorical dependent variable based on one or more independent variables \n",
    "- Used to estimate the probability of an outcome\n",
    "\n",
    "**Dependant variable (Y) |** The variable a given model estimates, also referred to as a response or outcome variable\n",
    "\n",
    "**Independent variable (X) |** A variable that explains trends in the dependent variable, also referred to as an explanatory or predictor variable.\n",
    "\n",
    "**Logistic Regression Model |** \n",
    "- $\\mu\\{Y|X\\} = Prob(Y = 1|X) = p$\n",
    "- $g(p) = \\beta_0 + \\beta_1X$ - (Link Function)\n",
    "\n",
    "**Link Function |** A nonlinear function that connects or links the dependent variable to the independent variable mathematically "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"2.-Foundations-of-Logistic-Regression\"></a>\n",
    "### 2. Foundations of Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Binomial Logistic Regression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A technique that models the probability of an observation falling into one of two categories, based on one or more independent variables.\n",
    "- This is a classification model\n",
    "\n",
    "**Binomial logistic regression linearity assumption |** There should be a linear relationship between each X variable and the logit of the probability that Y equals 1\n",
    "- $Odds = \\frac{p}{1-p}$\n",
    "\n",
    "**Logit(log-odds) |** The logarithm of the odds of a given probability. The logit of probability p is equal to the logarithm of p divided by 1 minus p.\n",
    "- $logit(p) = log(\\frac{p}{1-p})$\n",
    "\n",
    "**Logit in terms of X variables |** \n",
    "- $logit(p) = log(\\frac{p}{1-p}) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nXn$\n",
    "\n",
    "**Maximum Likelihood Estimation (MLE) |** A technique for estimating the beta parameters that maximize the likelihood of the model producing the observed data\n",
    "- The best logistic regression model estimates the set of beta coefficients that maximizes the likelihood of observing all of the sample data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"3.-Model-Assumptions\"></a>\n",
    "### 3. Model Assumptions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model assumptions are statements about the data that must be true in order to justify the use of a particular modeling technique\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.1 Logistic Regression Assumptions\n",
    "- **Linearity**\n",
    "- **Independent Observations**\n",
    "- **No Multicollinearity**\n",
    "- **No Extreme Outliers**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 3.1.1 Linearity\n",
    "\n",
    "Each predictor variable $(X_i)$ is linearly related to the outcome variable $(Y)$\n",
    "\n",
    "##### 3.1.2 Independent Observations \n",
    "\n",
    "Each observation in the dataset is independent\n",
    "\n",
    "##### 3.1.3 No Multicollinearity\n",
    "\n",
    "No two independent variables ($X_i$ and $X_j$) can be highly correlated with each other.\n",
    "- Variance Inflation Factors (VIF) quantifies how correlated each independent variable is with all of the other independent variables\n",
    "\n",
    "##### 3.1.4 No Extreme Outliers\n",
    "\n",
    "These can be identified once the model has been constructed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.2 Assumption Violations\n",
    "\n",
    "*`Lacking information on dealing with extreme outliers`*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 3.2.1 Linearity\n",
    "**Transform one or both of the variables**, such as taking the logarithm.\n",
    "- For example, if measuring the relationship between years of education and income, take the logarithm of the income variable and check if that helps the linear relationship.\n",
    "\n",
    "##### 3.2.2 Independent Observation \n",
    "**Take just a subset of the available data.**\n",
    "- If, for example, data is a survey including responses from people in the same household, responses may be correlated. Correct for this by just keeping the data of one person in each household.\n",
    "- Another example data on bike rental over a time period. If data collected every 15 minutes, the number of bikes rented out at 8:00 a.m. might correlate with the number of bikes rented out at 8:15 a.m. Perhaps the number of bikes rented out is independent if the data is taken once every 2 hours, instead of once every 15 minutes.\n",
    "\n",
    "##### 3.2.3 No Multicollinearity\n",
    "**Drop Variables**\n",
    "- Drop one or more variables that have high multicollinearity\n",
    "- Strategic variable selection:\n",
    "    - Forward Selection\n",
    "    - Backward elimination \n",
    "- Advanced variable selection:\n",
    "    - Ridge regression\n",
    "    - Lasso regression\n",
    "    - Elastic-net regression\n",
    "    - Principal component analysis(PSA)\n",
    "\n",
    "**Create new Variables**\n",
    "- Use existing data to create new variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"4.-Model-Interpretation\"></a>\n",
    "### 4. Model Interpretation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Confusion Matrix\n",
    "\n",
    "A graphical representation of how accurate a classifier is at predicting the labels for a categorical variable \n",
    "\n",
    "####  4.2 Evaluation Metrics \n",
    "- Precision \n",
    "- Recall\n",
    "- Accuracy\n",
    "\n",
    "##### 4.2.1 Precision\n",
    "The proportion of positive predictions that were true positives\n",
    "\n",
    "$Precision = \\frac{True Positives}{True Positives + False Positives}$\n",
    "\n",
    "##### 4.2.2 Recall\n",
    "The proportion of positives the model was able to identify correctly \n",
    "\n",
    "$Recall = \\frac{True Positives}{True Positives + False Negatives}$\n",
    "\n",
    "##### 4.2.3 Accuracy\n",
    "The proportion of data points that were correctly categorized\n",
    "\n",
    "$Accuracy = \\frac{True Positives + True Negatives}{Total Predictions}$\n",
    "\n",
    "##### 4.2.4 ROC Curves (Receiver Operating Characteristic).\n",
    "Used to visualize the performance of a classifier at different classification thresholds on a graph. A classification threshold in the context of a binary classification is the cutoff threshold for differentiating the positive class from the negative class.\n",
    "- Plots two key concepts\n",
    "    1. True Positive Rate\n",
    "    2. False Positive Rate\n",
    "**The more that the ROC curve hugs the top left corner of the plot, the better the model does at classifying the data.**\n",
    "\n",
    "##### 4.2.4 AUC \n",
    "Stands for Area Under ROC Curve. Provides an aggregate measure of performance across all possible classification thresholds. AUC ranges in value from 0.0 t0 1.0. A model that is 100% wrong has an AUC of 0 and a model predicting 100% correct has AUC of 1.0\n",
    "- An AUC of less than 0.5 indicates that the model performs worse than a random classifier \n",
    "- Python function: `metrics_roc_auc_score(y_test,y_pred)`\n",
    "\n",
    "#### 4.3 Considerations when choosing metrics\n",
    "\n",
    "##### 4.3.1 When to use Precision\n",
    "**Using precision as an evaluation metric is especially helpful in contexts where the cost of a false positive is quite high and much higher than the cost of a false negative.** For example, in the context of email spam detection, a false positive (predicting a non-spam email as spam) would be more costly than a false negative (predicting a spam email as non-spam). A non-spam email that is misclassified could contain important information, such as project status updates from a vendor to a client or assignment deadline announcements from an instructor to a class of students. \n",
    "\n",
    "##### 4.3.1 When to use Recall\n",
    "**Using recall as an evaluation metric is especially helpful in contexts where the cost of a false negative is quite high and much higher than the cost of a false positive.** For example, in the context of fraud detection among credit card transactions, a false negative (predicting a fraudulent credit card charge as non-fraudulent) would be more costly than a false positive (predicting a non-fraudulent credit card charge as fraudulent). A fraudulent credit card charge that is misclassified could lead to the customer losing money, undetected.\n",
    "\n",
    "##### 4.3.1 When to use Accuracy\n",
    "**It is helpful to use accuracy as an evaluation metric when you specifically want to know how much of the data at hand has been correctly categorized by the classifier.** Another scenario to consider: **accuracy is an appropriate metric to use when the data is balanced, in other words, when the data has a roughly equal number of positive examples and negative examples. Otherwise, accuracy can be biased.** For example, imagine that 95% of a dataset contains positive examples, and the remaining 5% contains negative examples. Then you train a logistic regression classifier on this data and use this classifier predict on this data. If you get an accuracy of 95%, that does not necessarily indicate that this classifier is effective. Since there is a much larger proportion of positive examples than negative examples, the classifier may be biased towards the majority class (positive) and thus the accuracy metric in this context may not be meaningful. When the data you are working with is imbalanced, consider either transforming it to be balanced or using a different evaluation metric other than accuracy. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"5.-Exploratory-Data-Analysis\"></a>\n",
    "### 5. Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard operational package imports.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Important imports for preprocessing, modeling, and evaluation.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Visualization package imports.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset into a DataFrame and save in a variable\n",
    "data = pd.read_csv(\"example_file.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 10 rows of the data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display number of rows, number of columns\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data type for each column. NB logistic regression models expect numeric data\n",
    "data.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Missing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.1 Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Start with .isna() to get booleans indicating whether each value in the data is missing\n",
    "data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Use .any(axis=1) to get booleans indicating whether there are any missing values along the columns in each row\n",
    "data.isna().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Use .sum() to get the number of rows that contain missing values\n",
    "data.isna().any(axis=1).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.2 Drop missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Use .dropna(axis=0) to indicate that you want rows which contain missing values to be dropped\n",
    "# Step 2. To update the DataFrame, reassign it to the result\n",
    "data = data.dropna(axis=0)\n",
    "\n",
    "# This is generally a good place to subset the data to avoid corrupting the original df so var should become data_subset but left as data for simplicity sake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure that the data does not contain any rows with missing values now\n",
    "\n",
    "# Step 1. Start with .isna() to get booleans indicating whether each value in the data is missing\n",
    "# Step 2. Use .any(axis=1) to get booleans indicating whether there are any missing values along the columns in each row\n",
    "# Step 3. Use .sum() to get the number of rows that contain missing values\n",
    "data.isna().any(axis=1).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.3 Convert Categorical Data to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of columns that need to be encoded\n",
    "columns_to_encode = ['cat_column_1', 'cat_column_2']\n",
    "\n",
    "# instantiate new df from the encoded df\n",
    "df_new = pd.get_dummies(df, columns=columns_to_encode, drop_first=True)\n",
    "\n",
    "df_new.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.3 Create training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into labels (y) and features (X).\n",
    "y = df3['left']\n",
    "\n",
    "X = df3.copy()\n",
    "X = X.drop('left', axis = 1)\n",
    "\n",
    "# Separate into train, validate, test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify= y, random_state = 0)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.30, stratify= y_train, random_state = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"6.-Model-Construction\"></a>\n",
    "### 6. Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a LogisticRegression model to the training data\n",
    "clf = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain parameter estimates\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of your model to visualize results using the seaborn package (this is a vizze generally used for simple linear regression not multiple variables)\n",
    "sns.regplot(x=\"independent variable\", y=\"dependant variable\", data= data, logistic= True, ci= None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to Answer:** What observations can be made from this initial visualization?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"7.-Model-Results\"></a>\n",
    "### 7. Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the outcome for the test dataset\n",
    "# Save predictions and print predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use predict_proba to output a probability.\n",
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use predict to output 0's and 1's.\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results by printing accuracy, precision, recall and F1 score\n",
    "\n",
    "print(\"Accuracy:\", \"%.6f\" % metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", \"%.6f\" % metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", \"%.6f\" % metrics.recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", \"%.6f\" % metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels = clf.classes_)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix = cm,display_labels = clf.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"8.-Model-Evaluation\"></a>\n",
    "### 8. Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Model Assumptions Check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.1 Linearity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot for each independent variable and the dependent variable.\n",
    "\n",
    "# Create a 1x2 plot figure.\n",
    "fig, axes = plt.subplots(1, 2, figsize = (8,4))\n",
    "\n",
    "# Create a scatterplot between X_1 and Y.\n",
    "sns.scatterplot(x = ols_data['X_1'], y = ols_data['Y'],ax=axes[0])\n",
    "\n",
    "# Set the title of the first plot.\n",
    "axes[0].set_title(\"X_1 and Y\")\n",
    "\n",
    "# Create a scatterplot between Social Media and Sales.\n",
    "sns.scatterplot(x = ols_data['X_2'], y = ols_data['Y'],ax=axes[1])\n",
    "\n",
    "# Set the title of the second plot.\n",
    "axes[1].set_title(\"X_2 and Y\")\n",
    "\n",
    "# Set the xlabel of the second plot.\n",
    "axes[1].set_xlabel(\"X_2\")\n",
    "\n",
    "# Use matplotlib's tight_layout() function to add space between plots for a cleaner appearance.\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to answer |** Is there a clear linear relationship in the scatterplot between Y and X variables? If yes then assumption is met."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.2 Independence Check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The independent observation assumption states that each observation in the dataset is independent. As each marketing promotion (i.e., row) is independent from one another, the independence assumption is not violated.\n",
    "- Consider whether each row of data is independent from one another is so then the independence assumption is not violated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.3 Multicollinearity Check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two common ways to check for multicollinearity are to:**\n",
    "\n",
    "* Create scatterplots to show the relationship between pairs of independent variables\n",
    "* Use the variance inflation factor to detect multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot of the data.\n",
    "sns.pairplot(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to answer:**\n",
    "\n",
    "1. Are the independent variables visibly linearly correlated?\n",
    "    - If no then assumption met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance inflation factor\n",
    "\n",
    "# Import variance_inflation_factor from statsmodels.\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Create a subset of the data with the continuous independent variables. \n",
    "X = ols_data[['X_1','X_2']]\n",
    "\n",
    "# Calculate the variance inflation factor for each variable.\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# Create a DataFrame with the VIF results for the column names in X.\n",
    "df_vif = pd.DataFrame(vif, index=X.columns, columns = ['VIF'])\n",
    "\n",
    "# Display the VIF results.\n",
    "df_vif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to answer:**\n",
    "\n",
    "A VIF value of 1 indicates that there is no correlation between the predictor variables, while a value of greater than 1 indicates that there is some correlation. Generally, a VIF value of 5 or above is considered to indicate a high degree of multicollinearity.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.4 Check for extreme outliers\n",
    "Note: that the assumption of no extreme outliers is not a formal assumption of logistic regression. However, extreme outliers can have a disproportionate impact on the model's results and influence the estimates of the coefficients. Therefore, it is a good practice to check for outliers in any regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the standardized residuals for each observation\n",
    "std_resid = clf.get_influence().resid_studentized_internal\n",
    "\n",
    "# Create a plot of the standardized residuals against the predicted values\n",
    "pred_vals = logit_model.predict(X)\n",
    "plt.scatter(pred_vals, std_resid)\n",
    "plt.axhline(y=2, color='r', linestyle='--')\n",
    "plt.axhline(y=-2, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Standardized Residuals')\n",
    "plt.title('Plot of Standardized Residuals vs. Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "# Look for any points that fall outside the range of +/- 2 or +/- 3 for the standardized residuals. These points may be considered as potential outliers.\n",
    "# If potential outliers found, investigate them further to determine whether they are genuine outliers or data errors. You may want to remove them from the analysis if they are confirmed as outliers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<a name=\"9.-Conclusions\"></a>\n",
    "### 9. Conclusions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.1 Drawing conclusions\n",
    "\n",
    "1. Interpret the confusion matrix\n",
    "    - Is there a significant difference between the false positives or false negatives that the model produced? \n",
    "\n",
    "2. What could be done to improve the model?\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1BgN3Lv1fx-AxyKSqB_2kM3dJ4mFBctv_",
     "timestamp": 1662734078308
    },
    {
     "file_id": "1ZYfhIvPRxnw7ghB_BsNQAMUorLXpAZs_",
     "timestamp": 1658889786811
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
